{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch,helpers\n",
    "from elasticsearch.helpers import bulk, streaming_bulk\n",
    "import uuid\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': '9200'}],timeout=30, max_retries=10, retry_on_timeout=True)\n",
    "#from pandasticsearch import Select\n",
    "import json\n",
    "import time\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "results = helpers.scan(es,\n",
    "    index=\"new_myindex\",\n",
    "    scroll = '2m',\n",
    "    size = 1000,\n",
    "    preserve_order=True,\n",
    "    query={'_source': ['content']},\n",
    "    request_timeout=3600\n",
    ")\n",
    "print(type(results))\n",
    "#from pandasticsearch import Select\n",
    "#pandas_df = Select.from_dict(results).to_pandas()\n",
    "#df = pd.concat(map(pd.DataFrame.from_dict, results), axis=1)['_source'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hits(hits):\n",
    "    df=pd.DataFrame()\n",
    "    for item in hits:\n",
    "        df = df.append(pd.DataFrame(item)) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrolling.. 1\n",
      "scrolling.. 2\n",
      "scrolling.. 3\n",
      "scrolling.. 4\n",
      "scrolling.. 5\n",
      "scrolling.. 6\n",
      "scrolling.. 7\n",
      "scrolling.. 8\n",
      "scrolling.. 9\n",
      "scrolling.. 10\n",
      "scrolling.. 11\n",
      "scrolling.. 12\n",
      "scrolling.. 13\n",
      "scrolling.. 14\n",
      "scrolling.. 15\n",
      "scrolling.. 16\n",
      "scrolling.. 17\n",
      "scrolling.. 18\n",
      "scrolling.. 19\n",
      "scrolling.. 20\n",
      "scrolling.. 21\n",
      "scrolling.. 22\n",
      "scrolling.. 23\n",
      "scrolling.. 24\n",
      "scrolling.. 25\n",
      "scrolling.. 26\n",
      "scrolling.. 27\n",
      "scrolling.. 28\n",
      "scrolling.. 29\n",
      "scrolling.. 30\n",
      "scrolling.. 31\n",
      "scrolling.. 32\n",
      "scrolling.. 33\n",
      "scrolling.. 34\n",
      "scrolling.. 35\n",
      "scrolling.. 36\n",
      "scrolling.. 37\n",
      "scrolling.. 38\n",
      "scrolling.. 39\n",
      "scrolling.. 40\n",
      "scrolling.. 41\n",
      "scrolling.. 42\n",
      "scrolling.. 43\n",
      "scrolling.. 44\n",
      "scrolling.. 45\n",
      "scrolling.. 46\n",
      "scrolling.. 47\n",
      "scrolling.. 48\n",
      "scrolling.. 49\n",
      "scrolling.. 50\n",
      "scrolling.. 51\n",
      "scrolling.. 52\n",
      "scrolling.. 53\n",
      "scrolling.. 54\n",
      "scrolling.. 55\n",
      "scrolling.. 56\n",
      "scrolling.. 57\n",
      "scrolling.. 58\n",
      "scrolling.. 59\n",
      "scrolling.. 60\n",
      "scrolling.. 61\n",
      "scrolling.. 62\n",
      "scrolling.. 63\n",
      "scrolling.. 64\n",
      "scrolling.. 65\n",
      "scrolling.. 66\n",
      "scrolling.. 67\n",
      "scrolling.. 68\n",
      "scrolling.. 69\n",
      "scrolling.. 70\n",
      "scrolling.. 71\n",
      "scrolling.. 72\n",
      "scrolling.. 73\n",
      "scrolling.. 74\n",
      "scrolling.. 75\n",
      "scrolling.. 76\n",
      "scrolling.. 77\n",
      "scrolling.. 78\n",
      "scrolling.. 79\n",
      "scrolling.. 80\n",
      "scrolling.. 81\n",
      "scrolling.. 82\n",
      "scrolling.. 83\n",
      "scrolling.. 84\n",
      "scrolling.. 85\n",
      "scrolling.. 86\n",
      "scrolling.. 87\n",
      "scrolling.. 88\n",
      "scrolling.. 89\n",
      "scrolling.. 90\n",
      "scrolling.. 91\n",
      "scrolling.. 92\n",
      "scrolling.. 93\n",
      "scrolling.. 94\n",
      "scrolling.. 95\n",
      "scrolling.. 96\n",
      "scrolling.. 97\n",
      "scrolling.. 98\n",
      "scrolling.. 99\n",
      "scrolling.. 100\n",
      "332.8810770511627\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "#Initialize the scroll\n",
    "#page = es.search(\n",
    "#  index = 'new_myindex',\n",
    " # scroll = '2m',\n",
    "  #search_type = 'scan',\n",
    "  #size = 10,\n",
    "  #body = {})\n",
    "start = time.time()\n",
    "page = es.search(\n",
    "    index='alldataindex',\n",
    "    #doc_type=\"_doc\",\n",
    "    scroll='30m',\n",
    "    size=10000,\n",
    "    _source=[\"content\"],\n",
    "    body={},\n",
    "    request_timeout=10000\n",
    ")\n",
    "sid = page['_scroll_id']\n",
    "scroll_size = len(page['hits']['hits'])\n",
    "\n",
    "df = df.append(json_normalize(page['hits']['hits']))\n",
    "#print(scroll_size)\n",
    "# Start scrolling\n",
    "i=1\n",
    "while (scroll_size > 0):\n",
    "    print(\"scrolling..\",i)\n",
    "    i=i+1\n",
    "    page = es.scroll(scroll_id = sid, scroll = '30m')\n",
    "    #df1 = process_hits(page['hits']['hits'])\n",
    "    #df=df.append(df1)\n",
    "    df = df.append(json_normalize(page['hits']['hits']))\n",
    "    #print(df.head(1))\n",
    "    # Update the scroll ID\n",
    "    #es.clear_scroll(sid)\n",
    "    sid = page['_scroll_id']\n",
    "    # Get the number of results that we returned in the last scroll\n",
    "    scroll_size = len(page['hits']['hits'])\n",
    "    #print(\"scroll size: \" + str(scroll_size))\n",
    "    # Do something with the obtained page\n",
    "end = time.time() - start\n",
    "print(end)\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>_index</th>\n",
       "      <th>_score</th>\n",
       "      <th>_source.content</th>\n",
       "      <th>_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C7kplWsBcyYnpedmfvCc</td>\n",
       "      <td>alldataindex</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TWO THOUSAND... SIX HUNDRED AND SIXTY-SIX DOLL...</td>\n",
       "      <td>alldataindex_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DLkplWsBcyYnpedmfvCc</td>\n",
       "      <td>alldataindex</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Unleashing your entrepreneurial spirit towards...</td>\n",
       "      <td>alldataindex_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DbkplWsBcyYnpedmfvCc</td>\n",
       "      <td>alldataindex</td>\n",
       "      <td>1.0</td>\n",
       "      <td>When you're one of the country's leaders you p...</td>\n",
       "      <td>alldataindex_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DrkplWsBcyYnpedmfvCc</td>\n",
       "      <td>alldataindex</td>\n",
       "      <td>1.0</td>\n",
       "      <td>An Athlone GAA player owes his life to the qui...</td>\n",
       "      <td>alldataindex_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D7kplWsBcyYnpedmfvCc</td>\n",
       "      <td>alldataindex</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Emerson Electric (NYSE:EMR) has opened bullish...</td>\n",
       "      <td>alldataindex_type</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    _id        _index  _score  \\\n",
       "0  C7kplWsBcyYnpedmfvCc  alldataindex     1.0   \n",
       "1  DLkplWsBcyYnpedmfvCc  alldataindex     1.0   \n",
       "2  DbkplWsBcyYnpedmfvCc  alldataindex     1.0   \n",
       "3  DrkplWsBcyYnpedmfvCc  alldataindex     1.0   \n",
       "4  D7kplWsBcyYnpedmfvCc  alldataindex     1.0   \n",
       "\n",
       "                                     _source.content              _type  \n",
       "0  TWO THOUSAND... SIX HUNDRED AND SIXTY-SIX DOLL...  alldataindex_type  \n",
       "1  Unleashing your entrepreneurial spirit towards...  alldataindex_type  \n",
       "2  When you're one of the country's leaders you p...  alldataindex_type  \n",
       "3  An Athlone GAA player owes his life to the qui...  alldataindex_type  \n",
       "4  Emerson Electric (NYSE:EMR) has opened bullish...  alldataindex_type  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "p = i/10000\n",
    "print(p.is_integer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list1=[]\n",
    "for item in results:\n",
    "    dict1={}\n",
    "    dict1['content']= item['_source']['content']\n",
    "    list1.append(dict1)\n",
    "df1=pd.DataFrame(list1)\n",
    "print(len(df1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
